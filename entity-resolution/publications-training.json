{"distinct": [{"__class__": "tuple", "__value__": [{"identifier": "10.5281/zenodo.7749108", "name": "adjudication and resolution of islamic finance disputes in non-muslim states: an analysis of islamic law with reference to international law", "url": "https://zenodo.org/api/records/7749108", "author": "sohail amjad; nagina riaz", "description": "an analysis of the growth of multi trillion islamic finance industry shows its huge importance and attraction for the stake holders but the lack of serious narrative and attitude towards resolution of disputes in islamic financial contracts is degrading its rapid growth and failing to maintain trust of muslims as well as non-muslim stake holders. immediate attention is needed from the scholars of islamic as well as international law to provide a route map and code of resolution and litigation towards adjudication of islamic finance disputes. this qualitative work analyzes the legal framework for islamic finance law in non-muslim jurisdictions in the light of teachings of muslim jurists and international law with reference to selected legal systems. this research finds that there is an immediate need of a structured code for the resolution of islamic finance disputes and suggests that adr and other legal remedies available in islamic context as well as international conventions shall be implemented immediately to resolve prevailing issues and disputes.", "datePublished": "17-03-23", "source_name": "zenodo", "source_identifier": "7749108", "source_url": "https://zenodo.org/records/7749108"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/72.554203", "name": "adaptive color segmentation-a comparison of neural and statistical methods", "url": "https://openalex.org/w2166277517", "author": "enno littmann; helge ritter", "description": "with the availability of more powerful computers it is nowadays possible to perform pixel based operations on real camera images even in full color space. new adaptive classification tools like neural networks make develop special-purpose object detectors that can segment arbitrary objects with a complex distribution feature space after training one or several previously labeled image(s). the paper focuses detailed comparison approach local linear maps (llms) classifier normal distributions. proposed segmentation method uses information estimate membership probability object, respectively, background class. applied recognition and localization human hands laboratory scenes.", "datePublished": "01-01-97", "source_name": "openalex", "source_identifier": "w2166277517", "source_url": "https://openalex.org/w2166277517"}, {"identifier": "10.5281/zenodo.8403782", "name": "architecting the future: a vision for using large language models to enable open science", "url": "https://zenodo.org/api/records/8403782", "author": "bugbee, kaylin; ramachandran, rahul", "description": "this document outlines our thoughts on the need for open science principles as it relates to using large language models (llms) in data systems. we describe our ideas for open science principles to guide llm development and implementation. we also outline an\u00a0approach for an llm-enabled, open science search infrastructure.", "datePublished": "03-10-23", "source_name": "zenodo", "source_identifier": "8403782", "source_url": "https://zenodo.org/records/8403782"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1007/s00216-016-9652-3", "name": "a visual assay and spectrophotometric determination of llm-105 explosive using detection of gold nanoparticle aggregation at two ph values", "url": "https://doi.org/10.1007/s00216-016-9652-3", "author": "yang cheng; yi he", "description": "we report a simple, rapid, and sensitive assay for visual and spectrophotometric detection of the 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) explosive. the assay is based on different interactions between llm-105 and gold nanoparticle (aunp) dispersions at two ph values, leading to the formation of dispersed or aggregated aunps. two aunp dispersions at two ph values were applied to recognize and detect llm-105 instead of traditional aunp dispersion under an aptotic ph to improve the anti-interference ability. the developed assay showed excellent sensitivity with a detection limit of 3\u00a0ng/ml, and the presence of as low as 0.2\u00a0\u03bcg/ml llm-105 can be directly detected with the bare eye. this sensitivity is about six orders of magnitude higher than that of the reported traditional assays. additionally, the assay exhibited good selectivity toward llm-105 over other explosives, sulfur-containing compounds, and amines. graphical abstract a simple, sensitive, and selective assay for llm-105 was developed based on the ph-dependent interaction between the llm-105 explosive and gold nanoparticle dispersion.", "datePublished": "26-05-16", "source_name": "openaire products", "source_identifier": "doi_dedup___::0f7d8ab8469519dfaf3e2f52e599f218", "source_url": "https://doi.org/10.1007/s00216-016-9652-3"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/tii.2019.2912625", "name": "an interpretable fuzzy dbn-based classifier for indoor user movement prediction in ambient assisted living applications", "url": "https://ieeexplore.ieee.org/document/8695137/", "author": "xiongtao zhang; fu-lai chung; shitong wang", "description": "in this paper, an interpretable fuzzy deep belief network (dbn)-based classifier called deep belief networks-based takagi-sugeno-kang fuzzy classifier (dbn-tsk-fc) is created for indoor user movement prediction in ambient assisted living applications. with its promising classification performance, dbn-tsk-fc features sharing both the powerful neural representation ability of a dbn and the strong uncertainty-handling capability of an interpretable fuzzy representation. on the one hand, dbn-tsk-fc builds its interpretable fuzzy representation in a hierarchical way by applying the classical fuzzy clustering algorithm fcm to obtain fuzzy partitions on the training dataset. then, it forms interpretable antecedent parts of fuzzy rules as the corresponding fuzzy representation. on the other hand, dbn-tsk-fc builds its dbn-based neural representation in the other hierarchical way. that is, it applies the existing unsupervised dbn pretraining on the training dataset and then takes the neural representation of all the hidden nodes in the top layer of the corresponding dbn as the set of consequent variables of fuzzy rules. in this approach, both the interpretable fuzzy representation and the dbn-based neural representation are further fused to form the corresponding fuzzy rules quickly by using the least learning machine (llm) on both the fuzzy rules and the labeling information of the original dataset. therefore, dbn-tsk-fc is essentially a deep tsk fuzzy classifier from the perspective of fuzzy rules, and it indeed avoids the very slow fine-tuning training required after the unsupervised pretraining of the existing dbn learning. the experimental results on the movementaal_rss dataset indicate the effectiveness of the proposed classifier dbn-tsk-fc.", "datePublished": "22-04-19", "source_name": "ieee", "source_identifier": "8695137", "source_url": "https://ieeexplore.ieee.org/document/8695137/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.22364/bjmc.2023.11.3.04", "name": "apple and pear scab expert system.", "url": "https://dblp.org/rec/journals/bjmc/apeinanszll23", "author": "llmars apeinans; imants zarembo; gunars lacis; lienite litavniece", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "21845", "source_url": "https://dblp.org/rec/journals/bjmc/apeinanszll23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.48550/arxiv.2303.12810", "name": "are llms the master of all trades? : exploring domain-agnostic reasoning skills of llms.", "url": "https://dblp.org/rec/journals/corr/abs-2303-12810", "author": "shrivats agrawal", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "283229", "source_url": "https://dblp.org/rec/journals/corr/abs-2303-12810"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/tii.2019.2912625", "name": "an interpretable fuzzy dbn-based classifier for indoor user movement prediction in ambient assisted living applications", "url": "https://ieeexplore.ieee.org/document/8695137/", "author": "xiongtao zhang; fu-lai chung; shitong wang", "description": "in this paper, an interpretable fuzzy deep belief network (dbn)-based classifier called deep belief networks-based takagi-sugeno-kang fuzzy classifier (dbn-tsk-fc) is created for indoor user movement prediction in ambient assisted living applications. with its promising classification performance, dbn-tsk-fc features sharing both the powerful neural representation ability of a dbn and the strong uncertainty-handling capability of an interpretable fuzzy representation. on the one hand, dbn-tsk-fc builds its interpretable fuzzy representation in a hierarchical way by applying the classical fuzzy clustering algorithm fcm to obtain fuzzy partitions on the training dataset. then, it forms interpretable antecedent parts of fuzzy rules as the corresponding fuzzy representation. on the other hand, dbn-tsk-fc builds its dbn-based neural representation in the other hierarchical way. that is, it applies the existing unsupervised dbn pretraining on the training dataset and then takes the neural representation of all the hidden nodes in the top layer of the corresponding dbn as the set of consequent variables of fuzzy rules. in this approach, both the interpretable fuzzy representation and the dbn-based neural representation are further fused to form the corresponding fuzzy rules quickly by using the least learning machine (llm) on both the fuzzy rules and the labeling information of the original dataset. therefore, dbn-tsk-fc is essentially a deep tsk fuzzy classifier from the perspective of fuzzy rules, and it indeed avoids the very slow fine-tuning training required after the unsupervised pretraining of the existing dbn learning. the experimental results on the movementaal_rss dataset indicate the effectiveness of the proposed classifier dbn-tsk-fc.", "datePublished": "22-04-19", "source_name": "ieee", "source_identifier": "8695137", "source_url": "https://ieeexplore.ieee.org/document/8695137/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": "10.1109/isi58743.2023.10297139", "name": "a two-stage prompt learning method for jointly predicting topic and personality", "url": "https://ieeexplore.ieee.org/document/10297139/", "author": "yilin wu; minjie yuan; yuxuan song; liping chen; chenyu yuan; qiudan li", "description": "accurate personality prediction can help management departments analyze users' behaviors and make informed decisions effectively. existing text-based personality prediction studies mainly rely on deep neural networks or pre-trained language models to extract semantic information and personality traits. however, the text's topic and label description may provide additional personality clues. this paper proposes a topic and personality prediction method based on a large language model (llm), which utilizes a two-stage prompt strategy to mine the interaction between the topic and personality information. additionally, labels' descriptions are incorporated to construct cue-based prompts, and a fine-tuning approach is adopted to optimize the model's performance. experiments on two datasets show the efficacy of the proposed model.", "datePublished": "01-11-23", "source_name": "ieee", "source_identifier": "10297139", "source_url": "https://ieeexplore.ieee.org/document/10297139/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1007/s00216-016-9652-3", "name": "a visual assay and spectrophotometric determination of llm-105 explosive using detection of gold nanoparticle aggregation at two ph values", "url": "https://doi.org/10.1007/s00216-016-9652-3", "author": "yang cheng; yi he", "description": "we report a simple, rapid, and sensitive assay for visual and spectrophotometric detection of the 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) explosive. the assay is based on different interactions between llm-105 and gold nanoparticle (aunp) dispersions at two ph values, leading to the formation of dispersed or aggregated aunps. two aunp dispersions at two ph values were applied to recognize and detect llm-105 instead of traditional aunp dispersion under an aptotic ph to improve the anti-interference ability. the developed assay showed excellent sensitivity with a detection limit of 3\u00a0ng/ml, and the presence of as low as 0.2\u00a0\u03bcg/ml llm-105 can be directly detected with the bare eye. this sensitivity is about six orders of magnitude higher than that of the reported traditional assays. additionally, the assay exhibited good selectivity toward llm-105 over other explosives, sulfur-containing compounds, and amines. graphical abstract a simple, sensitive, and selective assay for llm-105 was developed based on the ph-dependent interaction between the llm-105 explosive and gold nanoparticle dispersion.", "datePublished": "26-05-16", "source_name": "openaire products", "source_identifier": "doi_dedup___::0f7d8ab8469519dfaf3e2f52e599f218", "source_url": "https://doi.org/10.1007/s00216-016-9652-3"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1145/3618257.3624845", "name": "an llm-based framework for fingerprinting internet-connected devices.", "url": "https://dblp.org/rec/conf/imc/sarabiyl23", "author": "armin sarabi; tongxin yin; mingyan liu", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "224839", "source_url": "https://dblp.org/rec/conf/imc/sarabiyl23"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/icme55011.2023.00014", "name": "action-gpt: leveraging large-scale language models for improved and generalized action generation", "url": "https://ieeexplore.ieee.org/document/10219779/", "author": "sai shashank kalakonda; shubh maheshwari; ravi kiran sarvadevabhatla", "description": "we introduce action-gpt, a plug-and-play framework for incorporating large language models (llms) into text-based action generation models. action phrases in current motion capture datasets contain minimal and to-the-point information. by carefully crafting prompts for llms, we generate richer and fine-grained descriptions of the action. we show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. we introduce a generic approach compatible with stochastic (e.g. vae-based) and deterministic (e.g. motionclip) text-to-motion models. in addition, the approach enables multiple text descriptions to be utilized. our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple llm-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. code and pretrained models are available at https://actiongpt.github.io.", "datePublished": "25-08-23", "source_name": "ieee", "source_identifier": "10219779", "source_url": "https://ieeexplore.ieee.org/document/10219779/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/icalt58122.2023.00072", "name": "ai-assisted learning with chatgpt and large language models: implications for higher education", "url": "https://ieeexplore.ieee.org/document/10260931/", "author": "samuli laato; benedikt morschheuser; juho hamari; jari bj\u00f6rne", "description": "the recent progress in generative ai models, particularly large language models (llms), has brought about a transformation in the field of education. conversational llm services, such as google's bard and openai's chatgpt, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. in this paper, we observe chatgpt to explore how llm services impact learning and instruction in higher education. first, we mapped the capabilities of the system by reviewing the grey literature on chatgpt and using the system ourselves for two months. second, we selected a bachelor level computer science curriculum from a finnish university, and examined the impact of chatgpt on the offered courses. as an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of ai-assisted learning in universities and beyond.", "datePublished": "29-09-23", "source_name": "ieee", "source_identifier": "10260931", "source_url": "https://ieeexplore.ieee.org/document/10260931/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.1109/icalt58122.2023.00072", "name": "ai-assisted learning with chatgpt and large language models: implications for higher education", "url": "https://ieeexplore.ieee.org/document/10260931/", "author": "samuli laato; benedikt morschheuser; juho hamari; jari bj\u00f6rne", "description": "the recent progress in generative ai models, particularly large language models (llms), has brought about a transformation in the field of education. conversational llm services, such as google's bard and openai's chatgpt, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. in this paper, we observe chatgpt to explore how llm services impact learning and instruction in higher education. first, we mapped the capabilities of the system by reviewing the grey literature on chatgpt and using the system ourselves for two months. second, we selected a bachelor level computer science curriculum from a finnish university, and examined the impact of chatgpt on the offered courses. as an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of ai-assisted learning in universities and beyond.", "datePublished": "29-09-23", "source_name": "ieee", "source_identifier": "10260931", "source_url": "https://ieeexplore.ieee.org/document/10260931/"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": "10.1145/2501626.2501632", "name": "a software-only scheme for managing heap data on limited local memory(llm) multicore processors", "url": "https://openalex.org/w2009667616", "author": "ke bai; aviral shrivastava", "description": "this article presents a scheme for managing heap data in the local memory present each core of limited (llm) multicore architecture. although semi-automatically with software cache is feasible, it may require modifications other thread codes. crossthread are very difficult to code and debug, will become more complex challenging as we increase number cores. in this article, propose an intuitive programming interface, which automatic scalable management. besides, embedded applications, where maximum size can be profiled, several optimizations on our management significantly decrease library overheads. our experiments benchmarks from mibench executing sony playstation 3 show that natural use, if know data, improve application performance by average 14%.", "datePublished": "01-08-13", "source_name": "openalex", "source_identifier": "w2009667616", "source_url": "https://openalex.org/w2009667616"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.5281/zenodo.7749108", "name": "adjudication and resolution of islamic finance disputes in non-muslim states: an analysis of islamic law with reference to international law", "url": "https://zenodo.org/api/records/7749108", "author": "sohail amjad; nagina riaz", "description": "an analysis of the growth of multi trillion islamic finance industry shows its huge importance and attraction for the stake holders but the lack of serious narrative and attitude towards resolution of disputes in islamic financial contracts is degrading its rapid growth and failing to maintain trust of muslims as well as non-muslim stake holders. immediate attention is needed from the scholars of islamic as well as international law to provide a route map and code of resolution and litigation towards adjudication of islamic finance disputes. this qualitative work analyzes the legal framework for islamic finance law in non-muslim jurisdictions in the light of teachings of muslim jurists and international law with reference to selected legal systems. this research finds that there is an immediate need of a structured code for the resolution of islamic finance disputes and suggests that adr and other legal remedies available in islamic context as well as international conventions shall be implemented immediately to resolve prevailing issues and disputes.", "datePublished": "17-03-23", "source_name": "zenodo", "source_identifier": "7749108", "source_url": "https://zenodo.org/records/7749108"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.1109/icme55011.2023.00014", "name": "action-gpt: leveraging large-scale language models for improved and generalized action generation", "url": "https://ieeexplore.ieee.org/document/10219779/", "author": "sai shashank kalakonda; shubh maheshwari; ravi kiran sarvadevabhatla", "description": "we introduce action-gpt, a plug-and-play framework for incorporating large language models (llms) into text-based action generation models. action phrases in current motion capture datasets contain minimal and to-the-point information. by carefully crafting prompts for llms, we generate richer and fine-grained descriptions of the action. we show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. we introduce a generic approach compatible with stochastic (e.g. vae-based) and deterministic (e.g. motionclip) text-to-motion models. in addition, the approach enables multiple text descriptions to be utilized. our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple llm-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. code and pretrained models are available at https://actiongpt.github.io.", "datePublished": "25-08-23", "source_name": "ieee", "source_identifier": "10219779", "source_url": "https://ieeexplore.ieee.org/document/10219779/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1007/s00216-016-9652-3", "name": "a visual assay and spectrophotometric determination of llm-105 explosive using detection of gold nanoparticle aggregation at two ph values", "url": "https://doi.org/10.1007/s00216-016-9652-3", "author": "yang cheng; yi he", "description": "we report a simple, rapid, and sensitive assay for visual and spectrophotometric detection of the 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) explosive. the assay is based on different interactions between llm-105 and gold nanoparticle (aunp) dispersions at two ph values, leading to the formation of dispersed or aggregated aunps. two aunp dispersions at two ph values were applied to recognize and detect llm-105 instead of traditional aunp dispersion under an aptotic ph to improve the anti-interference ability. the developed assay showed excellent sensitivity with a detection limit of 3\u00a0ng/ml, and the presence of as low as 0.2\u00a0\u03bcg/ml llm-105 can be directly detected with the bare eye. this sensitivity is about six orders of magnitude higher than that of the reported traditional assays. additionally, the assay exhibited good selectivity toward llm-105 over other explosives, sulfur-containing compounds, and amines. graphical abstract a simple, sensitive, and selective assay for llm-105 was developed based on the ph-dependent interaction between the llm-105 explosive and gold nanoparticle dispersion.", "datePublished": "26-05-16", "source_name": "openaire products", "source_identifier": "doi_dedup___::0f7d8ab8469519dfaf3e2f52e599f218", "source_url": "https://doi.org/10.1007/s00216-016-9652-3"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://doi.org/10.1039/d0cp02159h", "author": "ying yin; hongzhen li; qian yu; longyu liao; jinshan li; heliang sui; chuande zhao", "description": "2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) is a representative of the new generation of low-sensitivity energetic materials and has been applied extensively in formulations as an insensitive high-energetic ingredient. although the initial thermal decomposition mechanism of llm-105 has been studied based on quantum chemical calculations, the internal mechanism of the two-step thermal decomposition still lacks experimental research. thus, this study involves a detailed experimental study to reveal the mechanism of the two-step thermal decomposition of llm-105. the results showed that llm-105 decay was a consecutive reaction. the first-step reaction dominated the early stage of the llm-105 decomposition, and its products participated in the reaction of the second step. the cleavage of no2 and nh2 groups of llm-105 mainly occurred in the first step, while gaseous products no and c2n2 were released during the second reaction step. the first-step reaction had a higher oxygen consumption rate and a lower carbon consumption rate, producing more heat due to more extensive oxidation of the carbon backbone. the difference in the oxidative ability and reaction rate between the two steps resulted in a two-step exothermic and mass loss behavior. this study provides further insights into the entire reaction process of llm-105 and would be helpful for its better application and for the design of new explosives.", "datePublished": "01-01-20", "source_name": "openaire products", "source_identifier": "doi_dedup___::a4e3ca635e6a69058303d9f593edfc17", "source_url": "https://doi.org/10.1039/d0cp02159h"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.5281/zenodo.7749108", "name": "adjudication and resolution of islamic finance disputes in non-muslim states: an analysis of islamic law with reference to international law", "url": "https://zenodo.org/api/records/7749108", "author": "sohail amjad; nagina riaz", "description": "an analysis of the growth of multi trillion islamic finance industry shows its huge importance and attraction for the stake holders but the lack of serious narrative and attitude towards resolution of disputes in islamic financial contracts is degrading its rapid growth and failing to maintain trust of muslims as well as non-muslim stake holders. immediate attention is needed from the scholars of islamic as well as international law to provide a route map and code of resolution and litigation towards adjudication of islamic finance disputes. this qualitative work analyzes the legal framework for islamic finance law in non-muslim jurisdictions in the light of teachings of muslim jurists and international law with reference to selected legal systems. this research finds that there is an immediate need of a structured code for the resolution of islamic finance disputes and suggests that adr and other legal remedies available in islamic context as well as international conventions shall be implemented immediately to resolve prevailing issues and disputes.", "datePublished": "17-03-23", "source_name": "zenodo", "source_identifier": "7749108", "source_url": "https://zenodo.org/records/7749108"}, {"identifier": "10.5281/zenodo.7783710", "name": "automatically semantically augmenting llm prompts (for code summarization)", "url": "https://doi.org/10.5281/zenodo.7783710", "author": "blinded", "description": "placeholder", "datePublished": "28-03-23", "source_name": "openaire products", "source_identifier": "doi_dedup___::326466c0045804138da54ed0ba0e7ea9", "source_url": "https://doi.org/10.5281/zenodo.7783710"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.5281/zenodo.7783710", "name": "automatically semantically augmenting llm prompts (for code summarization)", "url": "https://doi.org/10.5281/zenodo.7783710", "author": "blinded", "description": "placeholder", "datePublished": "28-03-23", "source_name": "openaire products", "source_identifier": "doi_dedup___::326466c0045804138da54ed0ba0e7ea9", "source_url": "https://doi.org/10.5281/zenodo.7783710"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/icciautom.2011.6356710", "name": "adaptive locally-linear-models-based fault detection and diagnosis for unmeasured states and unknown faults", "url": "https://ieeexplore.ieee.org/document/6356710/", "author": "farzad soltanian; ahmad akbari alvanagh; mohammad javad khosrowjerdi", "description": "today the problem of fault detection and diagnosis (fdd) is considered as an important and essential counterpart of control engineering systems. because of importance and existence of faults that don't have a known structure in control system, i.e., fault occurred because of tangle of complex factors, in this paper a lipschitz nonlinear system with unmeasured states and unknown faults is considered and a novel fdd architecture for it is presented. a neuro/fuzzy model consisting of few locally linear models (llms) with on-line updated centers and width vectors is used to approximate the model of the fault. a nonlinear observer is used to estimate the states of the system that are inputs to llms. the stability analysis of system is carried out via lyapunov theory, from which the parameter updating rules are derived. at the end of this paper some numerical simulation is given to show the effectiveness of the method.", "datePublished": "24-11-12", "source_name": "ieee", "source_identifier": "6356710", "source_url": "https://ieeexplore.ieee.org/document/6356710/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/mfi-2003.2003.1232674", "name": "altair: automatic location tracking system using active ir-tag", "url": "https://ieeexplore.ieee.org/document/1232674/", "author": "m. sakata; y. yasumuro; m. imura; y. manabe; k. chihara", "description": "this paper proposes a new location-awareness system altair (automatic location tracking system using active ir-tag) that automatically detects and tracks the location of the mobile pc (personal computer) users. ir-tag (infrared) is a small electrical device to indicate its location by emitting ir light and reliable detected by a camera with ir-pass filter. ir-tag is installed on a mobile pc, which has wireless lan (local area network) connection so that altair controls lighting pattern and activating time of individual ir-tag through the network. altair identifies visually detected position of the ir-tag with the ip (internet protocol) address whom the system requires to change the lighting pattern. utilizing dhcp (dynamic host configuration protocol) service, altair stars to aware the position of the mobile pc user when he/she enters the area within altair's coverage. prototype altair shows the effective performance for tracking and recognizing multiple users' positions in an office environment.", "datePublished": "23-09-03", "source_name": "ieee", "source_identifier": "1232674", "source_url": "https://ieeexplore.ieee.org/document/1232674/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.22364/bjmc.2023.11.3.04", "name": "apple and pear scab expert system.", "url": "https://dblp.org/rec/journals/bjmc/apeinanszll23", "author": "llmars apeinans; imants zarembo; gunars lacis; lienite litavniece", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "21845", "source_url": "https://dblp.org/rec/journals/bjmc/apeinanszll23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": "10.1109/emr.2023.3272799", "name": "accelerating innovation with generative ai: ai-augmented digital prototyping and innovation methods", "url": "https://ieeexplore.ieee.org/document/10115412/", "author": "volker bilgram; felix laarmann", "description": "easy-to-use generative artificial intelligence (ai) is democratizing the use of ai in innovation management and may significantly change the way how we work and innovate. in this article, we show how large language models (llms), such as generative pretrained transformer (gpt), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. drawing on six months of experimenting with llms in internal and client innovation projects, we share first-hand experiences and concrete examples of ai-assisted approaches. the article highlights a large variety of use cases for generative ai ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role llms may play in future knowledge management systems. moreover, we argue that generative ai may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. our experiences also provide insights into how human innovation teams purposively and effectively interact with ais and integrate them into their workflows.", "datePublished": "04-05-23", "source_name": "ieee", "source_identifier": "10115412", "source_url": "https://ieeexplore.ieee.org/document/10115412/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.ejor.2018.02.009", "name": "a new hybrid classification algorithm for customer churn prediction based on logistic regression and decision trees", "url": "https://openalex.org/w2792328488", "author": "arno de caigny; kristof coussement; koen w. de bock", "description": "decision trees and logistic regression are two very popular algorithms in customer churn prediction with strong predictive performance good comprehensibility. despite these strengths, decision tend to have problems handle linear relations between variables has difficulties interaction effects variables. therefore a new hybrid algorithm, the logit leaf model (llm), is proposed better classify data. the idea behind llm that different models constructed on segments of data rather than entire dataset lead while maintaining comprehensibility from leaves. consists stages: segmentation phase phase. in first stage identified using rules second created for every this tree. this approach benchmarked against trees, regression, random forests regards area under receiver operating characteristics curve (auc) top decile lift (tdl) used measure which scores significantly its building blocks performs at least as well more advanced ensemble methods trees. comprehensibility addressed by case study we observe some key benefits compared or regression.", "datePublished": "01-09-18", "source_name": "openalex", "source_identifier": "w2792328488", "source_url": "https://openalex.org/w2792328488"}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.1080/15389588.2018.1432858", "name": "analysis of the influence of passenger vehicles front-end design on pedestrian lower extremity injuries by means of the llms model", "url": "https://openalex.org/w2789464225", "author": "alessandro scattina; fuhao mo; catherine masson; massimiliano avalle; pierre\u2010jean arnoux", "description": "this work aims at investigating the influence of some front-end design parameters a passenger vehicle on behavior and damage occurring in human lower limbs when impacted an accident.the analysis is carried out by means finite element using generic car model for safety (llms) purpose pedestrian safety. considering standardized impact procedure (as 2003/12/ec directive), parametric analysis, through experiments plan, was performed. various material properties, bumper thickness, position higher beams, pedestrian, were made variable order to identify how they injury occurrence. the prediction evaluated from knee lateral flexion, ligament elongation, state stress bone structure.the results highlighted that offset between beams most influential parameter affecting response. smaller or absent considering other responses considered parameters. stiffness characteristics are, instead, more notable tibia. even if optimal value variables could not be identified trends detected, with potential indicating strategies improvement.the front end against can improved optimizing its design. indicates improvement. in this work, each changed independently one time; future works, interaction also investigated. moreover, similar standard mechanical legform understand diversities correlations tools models.", "datePublished": "12-04-18", "source_name": "openalex", "source_identifier": "w2789464225", "source_url": "https://openalex.org/w2789464225"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://doi.org/10.1016/j.enmf.2020.12.001", "author": "xu rong; hongzhen li; chen dong; xiaoqing zhou; hao shilong; xin zhou", "description": "abstract   sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, and spherical shapes, were prepared using a solution crystallization method, and their crystal characteristics and sensitivity were investigated. it was found that the h50 values (impact sensitivity) of llm-105 vary within an extremely wide range of 33.8\u2013112.2\u202fcm and are mainly influenced by the particle morphology, crystal integrity, particle surface defects, and roughness, but are mostly independent of intracrystalline defects and particle sizes. the friction sensitivities of all samples are zero and are unaffected by the crystal characteristics. the g50 values (shock sensitivity) are within the range of 0\u20136.9\u202fmm, increasing with decreasing particle sizes and the apparent crystal density. notably, llm-105 crystals with a spherical shape, good integrity, smooth surface, and fewer defects are insensitive to impact and shock impulse. the relationships between the crystal characteristics and the sensitivity of llm-105 are extremely complex and show some abnormal phenomena, which can be attributed to the crystal packing style and aggregated microstructures of llm-105.", "datePublished": "01-12-20", "source_name": "openaire products", "source_identifier": "doi_________::737c8c201b09102a84bacf3fa4022ba4", "source_url": "https://doi.org/10.1016/j.enmf.2020.12.001"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.1109/itoec57671.2023.10291525", "name": "a llm-based simulation scenario aided generation method", "url": "https://ieeexplore.ieee.org/document/10291525/", "author": "junfeng zhang; yang zhang; minnan chu; shun yang; taolei zu", "description": "in the simulation training system, the generation of simulation scenarios is a basic problem that needs to be studied. firstly, expounds on the technical characteristics of llm and knowledge graph; then structurally describe the simulation scenario related content, and build scenario knowledge graph; according to the characteristics of scenario aided generation, a simulation scenario generation method based on llm is proposed, which uses prompt to fuse knowledge graph and llm, next, the implementation steps of this method were elaborated; finally, the specific application proves that the method proposed in this paper is a good reference for the generation of simulation scenarios.", "datePublished": "30-10-23", "source_name": "ieee", "source_identifier": "10291525", "source_url": "https://ieeexplore.ieee.org/document/10291525/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.1109/isi58743.2023.10297139", "name": "a two-stage prompt learning method for jointly predicting topic and personality", "url": "https://ieeexplore.ieee.org/document/10297139/", "author": "yilin wu; minjie yuan; yuxuan song; liping chen; chenyu yuan; qiudan li", "description": "accurate personality prediction can help management departments analyze users' behaviors and make informed decisions effectively. existing text-based personality prediction studies mainly rely on deep neural networks or pre-trained language models to extract semantic information and personality traits. however, the text's topic and label description may provide additional personality clues. this paper proposes a topic and personality prediction method based on a large language model (llm), which utilizes a two-stage prompt strategy to mine the interaction between the topic and personality information. additionally, labels' descriptions are incorporated to construct cue-based prompts, and a fine-tuning approach is adopted to optimize the model's performance. experiments on two datasets show the efficacy of the proposed model.", "datePublished": "01-11-23", "source_name": "ieee", "source_identifier": "10297139", "source_url": "https://ieeexplore.ieee.org/document/10297139/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.5281/zenodo.8111952", "name": "automated domain modeling with large language models: a comparative study", "url": "https://zenodo.org/api/records/8111952", "author": "chen, kua; yang,yujing; chen, boqi; hern\u00e1ndez l\u00f3pez\t, jos\u00e9 antonio; mussbacher, gunter; varr\u00f3, d\u00e1niel", "description": "this paper describes a new approach of using llm to automate domain model generation.", "datePublished": "03-07-23", "source_name": "zenodo", "source_identifier": "8111952", "source_url": "https://zenodo.org/records/8111952"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/wcnc.2010.5506564", "name": "a new llms algorithm for antenna array beamforming", "url": "https://openalex.org/w1991469708", "author": "jalal abdulsayed srar; kah-seng chung; ali mansour", "description": "a new adaptive algorithm, called llms, which employs an array image factor, <sub xmlns:mml=\"http://www.w3.org/1998/math/mathml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i</sub> , sandwiched in between two least mean square (lms) sections, is proposed for different applications of beamforming. the convergence llms algorithm analyzed, terms mean square error, the presence additive white gaussian noise (awgn) modes operation; namely with either external reference or self-referencing. unlike earlier lms based schemes, make use step size adaptation to enhance their performance, derives its overall error signal by feeding back from second stage combine that first section. this results being less sensitive variations input signal-to-noise ratio as well sizes used. computer simulation show superior performance over conventional some more recent algorithms, such constrained-stability (cslms), and modified robust variable step size (mrvss) algorithms. also, operation remains stable even when corrupted awgn. it also shown performs rayleigh fading.", "datePublished": "01-04-10", "source_name": "openalex", "source_identifier": "w1991469708", "source_url": "https://openalex.org/w1991469708"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/emr.2023.3272799", "name": "accelerating innovation with generative ai: ai-augmented digital prototyping and innovation methods", "url": "https://ieeexplore.ieee.org/document/10115412/", "author": "volker bilgram; felix laarmann", "description": "easy-to-use generative artificial intelligence (ai) is democratizing the use of ai in innovation management and may significantly change the way how we work and innovate. in this article, we show how large language models (llms), such as generative pretrained transformer (gpt), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. drawing on six months of experimenting with llms in internal and client innovation projects, we share first-hand experiences and concrete examples of ai-assisted approaches. the article highlights a large variety of use cases for generative ai ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role llms may play in future knowledge management systems. moreover, we argue that generative ai may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. our experiences also provide insights into how human innovation teams purposively and effectively interact with ais and integrate them into their workflows.", "datePublished": "04-05-23", "source_name": "ieee", "source_identifier": "10115412", "source_url": "https://ieeexplore.ieee.org/document/10115412/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://doi.org/10.1016/j.enmf.2020.12.001", "author": "xu rong; hongzhen li; chen dong; xiaoqing zhou; hao shilong; xin zhou", "description": "abstract   sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, and spherical shapes, were prepared using a solution crystallization method, and their crystal characteristics and sensitivity were investigated. it was found that the h50 values (impact sensitivity) of llm-105 vary within an extremely wide range of 33.8\u2013112.2\u202fcm and are mainly influenced by the particle morphology, crystal integrity, particle surface defects, and roughness, but are mostly independent of intracrystalline defects and particle sizes. the friction sensitivities of all samples are zero and are unaffected by the crystal characteristics. the g50 values (shock sensitivity) are within the range of 0\u20136.9\u202fmm, increasing with decreasing particle sizes and the apparent crystal density. notably, llm-105 crystals with a spherical shape, good integrity, smooth surface, and fewer defects are insensitive to impact and shock impulse. the relationships between the crystal characteristics and the sensitivity of llm-105 are extremely complex and show some abnormal phenomena, which can be attributed to the crystal packing style and aggregated microstructures of llm-105.", "datePublished": "01-12-20", "source_name": "openaire products", "source_identifier": "doi_________::737c8c201b09102a84bacf3fa4022ba4", "source_url": "https://doi.org/10.1016/j.enmf.2020.12.001"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": "10.5281/zenodo.8304433", "name": "artifact of enhancing genetic improvement mutations using large language models", "url": "https://zenodo.org/api/records/8304433", "author": "alexander brownlee; james callan; karine even-mendoza; alina geiger; carol hanna; justyna petke; federica sarro; dominik sobania", "description": "this is the artefact of the paper adding llm to gin:\u00a0enhancing genetic improvement mutations using large language models\u00a0with additional data.\nthe code, llms prompt and experimental infrastructure, data from the evaluation, and results are available as open source at here. the code is also under the \u2018llm\u2019 branch of github.com/gintool/gin (commit 9fe9bdf;\u00a0branched from master commit 2359f57 pending full integration with gin).", "datePublished": "01-09-23", "source_name": "zenodo", "source_identifier": "8304433", "source_url": "https://zenodo.org/records/8304433"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/cai54212.2023.00147", "name": "a new method using llms for keypoints generation in qualitative data analysis", "url": "https://ieeexplore.ieee.org/document/10194998/", "author": "fengxiang zhao; fan yu; timothy trull; yi shang", "description": "qualitative data analysis (qda) is useful for identifying patterns, themes, and relationships among data. in this paper, we propose a new method that uses large language models (llms), such as gpt-based models, to improve qda, in ecological momentary assessment (ema) studies as an example, by automating keypoints extraction and relevance evaluation. experimental results on the ibm-argkp-2021 dataset show improved performance of the new method over existing work, achieving higher accuracy while reducing time and effort in the coding process of qda, and demonstrate the effectiveness of our proposed method in various application settings.", "datePublished": "02-08-23", "source_name": "ieee", "source_identifier": "10194998", "source_url": "https://ieeexplore.ieee.org/document/10194998/"}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}, {"identifier": "10.1109/tii.2019.2912625", "name": "an interpretable fuzzy dbn-based classifier for indoor user movement prediction in ambient assisted living applications", "url": "https://ieeexplore.ieee.org/document/8695137/", "author": "xiongtao zhang; fu-lai chung; shitong wang", "description": "in this paper, an interpretable fuzzy deep belief network (dbn)-based classifier called deep belief networks-based takagi-sugeno-kang fuzzy classifier (dbn-tsk-fc) is created for indoor user movement prediction in ambient assisted living applications. with its promising classification performance, dbn-tsk-fc features sharing both the powerful neural representation ability of a dbn and the strong uncertainty-handling capability of an interpretable fuzzy representation. on the one hand, dbn-tsk-fc builds its interpretable fuzzy representation in a hierarchical way by applying the classical fuzzy clustering algorithm fcm to obtain fuzzy partitions on the training dataset. then, it forms interpretable antecedent parts of fuzzy rules as the corresponding fuzzy representation. on the other hand, dbn-tsk-fc builds its dbn-based neural representation in the other hierarchical way. that is, it applies the existing unsupervised dbn pretraining on the training dataset and then takes the neural representation of all the hidden nodes in the top layer of the corresponding dbn as the set of consequent variables of fuzzy rules. in this approach, both the interpretable fuzzy representation and the dbn-based neural representation are further fused to form the corresponding fuzzy rules quickly by using the least learning machine (llm) on both the fuzzy rules and the labeling information of the original dataset. therefore, dbn-tsk-fc is essentially a deep tsk fuzzy classifier from the perspective of fuzzy rules, and it indeed avoids the very slow fine-tuning training required after the unsupervised pretraining of the existing dbn learning. the experimental results on the movementaal_rss dataset indicate the effectiveness of the proposed classifier dbn-tsk-fc.", "datePublished": "22-04-19", "source_name": "ieee", "source_identifier": "8695137", "source_url": "https://ieeexplore.ieee.org/document/8695137/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.ejor.2018.02.009", "name": "a new hybrid classification algorithm for customer churn prediction based on logistic regression and decision trees", "url": "https://openalex.org/w2792328488", "author": "arno de caigny; kristof coussement; koen w. de bock", "description": "decision trees and logistic regression are two very popular algorithms in customer churn prediction with strong predictive performance good comprehensibility. despite these strengths, decision tend to have problems handle linear relations between variables has difficulties interaction effects variables. therefore a new hybrid algorithm, the logit leaf model (llm), is proposed better classify data. the idea behind llm that different models constructed on segments of data rather than entire dataset lead while maintaining comprehensibility from leaves. consists stages: segmentation phase phase. in first stage identified using rules second created for every this tree. this approach benchmarked against trees, regression, random forests regards area under receiver operating characteristics curve (auc) top decile lift (tdl) used measure which scores significantly its building blocks performs at least as well more advanced ensemble methods trees. comprehensibility addressed by case study we observe some key benefits compared or regression.", "datePublished": "01-09-18", "source_name": "openalex", "source_identifier": "w2792328488", "source_url": "https://openalex.org/w2792328488"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://doi.org/10.1039/d0cp02159h", "author": "ying yin; hongzhen li; qian yu; longyu liao; jinshan li; heliang sui; chuande zhao", "description": "2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) is a representative of the new generation of low-sensitivity energetic materials and has been applied extensively in formulations as an insensitive high-energetic ingredient. although the initial thermal decomposition mechanism of llm-105 has been studied based on quantum chemical calculations, the internal mechanism of the two-step thermal decomposition still lacks experimental research. thus, this study involves a detailed experimental study to reveal the mechanism of the two-step thermal decomposition of llm-105. the results showed that llm-105 decay was a consecutive reaction. the first-step reaction dominated the early stage of the llm-105 decomposition, and its products participated in the reaction of the second step. the cleavage of no2 and nh2 groups of llm-105 mainly occurred in the first step, while gaseous products no and c2n2 were released during the second reaction step. the first-step reaction had a higher oxygen consumption rate and a lower carbon consumption rate, producing more heat due to more extensive oxidation of the carbon backbone. the difference in the oxidative ability and reaction rate between the two steps resulted in a two-step exothermic and mass loss behavior. this study provides further insights into the entire reaction process of llm-105 and would be helpful for its better application and for the design of new explosives.", "datePublished": "01-01-20", "source_name": "openaire products", "source_identifier": "doi_dedup___::a4e3ca635e6a69058303d9f593edfc17", "source_url": "https://doi.org/10.1039/d0cp02159h"}, {"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": "10.1109/iraniancee.2012.6292499", "name": "adaptive locally-linear-models-based fault tolerant control for humanoid robot with unknown faults", "url": "https://ieeexplore.ieee.org/document/6292499/", "author": "farzad soltanian; ahmad akbari alvanagh; mohammad javad khosrowjerdi", "description": "today the problem of fault tolerant control (ftc) is considered as an important and essential counterpart of control engineering systems. because of importance and existence of faults that don't have a known structure in control system, i.e., fault occurred because of tangle of complex factors, in this paper a humanoid robot with unknown faults is considered and a novel ftc architecture is presented. a neuro/fuzzy model consisting of a few locally linear models (llms) with on-line updated centers and width vectors is used to approximate the fault model. a linear estimator is employed to estimate the states of the system that are inputs to llms. the stability analysis of system is accomplished via lyapunov theory, from which the parameter updating rules are derived. at the end of this paper some numerical simulations are given to show the effectiveness of the proposed method.", "datePublished": "03-09-12", "source_name": "ieee", "source_identifier": "6292499", "source_url": "https://ieeexplore.ieee.org/document/6292499/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609288", "name": "a catalog of the wizard llm series", "url": "https://doi.org/10.48366/r609288", "author": "jennifer d\u2019souza", "description": "wizardlm is a llm based on llama trained using a new method, called evol-instruct, on complex instruction data. by using ai to \"evolve\" instructions, wizardlm outperforms similar llama-based llms trained on simpler instruction data. on the 6th of july, 2023, wizardlm v1.1 was released with significantly improved performance. this comparison juxtaposes all wizard llm variants based on their salient properties", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdkyodg="}, {"identifier": "10.1109/emr.2023.3272799", "name": "accelerating innovation with generative ai: ai-augmented digital prototyping and innovation methods", "url": "https://ieeexplore.ieee.org/document/10115412/", "author": "volker bilgram; felix laarmann", "description": "easy-to-use generative artificial intelligence (ai) is democratizing the use of ai in innovation management and may significantly change the way how we work and innovate. in this article, we show how large language models (llms), such as generative pretrained transformer (gpt), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. drawing on six months of experimenting with llms in internal and client innovation projects, we share first-hand experiences and concrete examples of ai-assisted approaches. the article highlights a large variety of use cases for generative ai ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role llms may play in future knowledge management systems. moreover, we argue that generative ai may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. our experiences also provide insights into how human innovation teams purposively and effectively interact with ais and integrate them into their workflows.", "datePublished": "04-05-23", "source_name": "ieee", "source_identifier": "10115412", "source_url": "https://ieeexplore.ieee.org/document/10115412/"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.48550/arxiv.2303.12810", "name": "are llms the master of all trades? : exploring domain-agnostic reasoning skills of llms.", "url": "https://dblp.org/rec/journals/corr/abs-2303-12810", "author": "shrivats agrawal", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "283229", "source_url": "https://dblp.org/rec/journals/corr/abs-2303-12810"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://ieeexplore.ieee.org/document/6090694/", "author": "panagiotis d. bamidis; evdokimos i. konstantinidis; antonis billis; christos frantzidis; magda tsolaki; walter hlauschek; efthyvoulos kyriacou; marios neofytou; constantinos s. pattichis", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "ieee", "source_identifier": "6090694", "source_url": "https://ieeexplore.ieee.org/document/6090694/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.ejor.2018.02.009", "name": "a new hybrid classification algorithm for customer churn prediction based on logistic regression and decision trees", "url": "https://openalex.org/w2792328488", "author": "arno de caigny; kristof coussement; koen w. de bock", "description": "decision trees and logistic regression are two very popular algorithms in customer churn prediction with strong predictive performance good comprehensibility. despite these strengths, decision tend to have problems handle linear relations between variables has difficulties interaction effects variables. therefore a new hybrid algorithm, the logit leaf model (llm), is proposed better classify data. the idea behind llm that different models constructed on segments of data rather than entire dataset lead while maintaining comprehensibility from leaves. consists stages: segmentation phase phase. in first stage identified using rules second created for every this tree. this approach benchmarked against trees, regression, random forests regards area under receiver operating characteristics curve (auc) top decile lift (tdl) used measure which scores significantly its building blocks performs at least as well more advanced ensemble methods trees. comprehensibility addressed by case study we observe some key benefits compared or regression.", "datePublished": "01-09-18", "source_name": "openalex", "source_identifier": "w2792328488", "source_url": "https://openalex.org/w2792328488"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r609546", "name": "a review of transformer models", "url": "https://doi.org/10.48366/r609546", "author": "jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d'souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza; jennifer d\u2019souza", "description": "the following is a review article https://orkg.org/review/r609355 surveying large language models published on the open research knowledge graph (orkg) platform. the orkg leverages the next-generation semantic publishing tools and applied them on scholarly communication. in particular, it stores machine-actionable structured contributions in its knowledge graph. as such this review is a first of its kind representing salient characteristics of llms (their main contributions) in a structured and semantic way on the orkg. the article might be particularly insightful in that it combines several structured llm descriptions via comparisons filtered as sections based on various organizations involved such as the llama series from meta, the pythia series from eleutherai, deepmind's chinchilla and other models, openllama from berkeley ai research, the wizard series from microsoft, etc. it concludes with a large-scale comparison of 87 different llms including the recent jais for the arabic language.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i2mdk1ndy="}, {"identifier": "10.1109/icme55011.2023.00014", "name": "action-gpt: leveraging large-scale language models for improved and generalized action generation", "url": "https://ieeexplore.ieee.org/document/10219779/", "author": "sai shashank kalakonda; shubh maheshwari; ravi kiran sarvadevabhatla", "description": "we introduce action-gpt, a plug-and-play framework for incorporating large language models (llms) into text-based action generation models. action phrases in current motion capture datasets contain minimal and to-the-point information. by carefully crafting prompts for llms, we generate richer and fine-grained descriptions of the action. we show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. we introduce a generic approach compatible with stochastic (e.g. vae-based) and deterministic (e.g. motionclip) text-to-motion models. in addition, the approach enables multiple text descriptions to be utilized. our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple llm-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. code and pretrained models are available at https://actiongpt.github.io.", "datePublished": "25-08-23", "source_name": "ieee", "source_identifier": "10219779", "source_url": "https://ieeexplore.ieee.org/document/10219779/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}, {"identifier": "10.1109/icme55011.2023.00014", "name": "action-gpt: leveraging large-scale language models for improved and generalized action generation", "url": "https://ieeexplore.ieee.org/document/10219779/", "author": "sai shashank kalakonda; shubh maheshwari; ravi kiran sarvadevabhatla", "description": "we introduce action-gpt, a plug-and-play framework for incorporating large language models (llms) into text-based action generation models. action phrases in current motion capture datasets contain minimal and to-the-point information. by carefully crafting prompts for llms, we generate richer and fine-grained descriptions of the action. we show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. we introduce a generic approach compatible with stochastic (e.g. vae-based) and deterministic (e.g. motionclip) text-to-motion models. in addition, the approach enables multiple text descriptions to be utilized. our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple llm-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. code and pretrained models are available at https://actiongpt.github.io.", "datePublished": "25-08-23", "source_name": "ieee", "source_identifier": "10219779", "source_url": "https://ieeexplore.ieee.org/document/10219779/"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}, {"identifier": "10.22364/bjmc.2023.11.3.04", "name": "apple and pear scab expert system.", "url": "https://dblp.org/rec/journals/bjmc/apeinanszll23", "author": "llmars apeinans; imants zarembo; gunars lacis; lienite litavniece", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "21845", "source_url": "https://dblp.org/rec/journals/bjmc/apeinanszll23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1117/12.612872", "name": "<title>formal tests for llm approaches using refined cockpit display technology</title>", "url": "https://openalex.org/w1993697266", "author": "randall c. davis; dennis w. wilt; james henion; keith alter; paul snow; john e. deaton", "description": "results are presented from formal flight and simulation experiments to test a new primary display (pfd)/refined multifunction (mfd) system, with computer generated dynamic pathway, as viable means for pilot accurately efficiently control navigate an aircraft. for control, the pfd uses highway-in-the-sky (hits) pathway synthetic vision terrain image of view outside aircraft, overlay all essential technical data. navigation, mfd provides moving map aid pilot. the total pfd/mfd system predictive method flying opposed reactive associated conventional needle dial instruments. fifteen low-to-average-experience subject pilots were selected compare instrumentation system. a non-precision global positioning (gps) area navigation (rnav) approach runway 20 at wakefield municipal airport, va, (akq) was used. hypothesis that intuitive nature will provide greater situational awareness, improved accuracy, less workload during in instrument meteorological conditions (imc) compared using round instrumentation.", "datePublished": "25-05-05", "source_name": "openalex", "source_identifier": "w1993697266", "source_url": "https://openalex.org/w1993697266"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}, {"identifier": "10.5281/zenodo.8111952", "name": "automated domain modeling with large language models: a comparative study", "url": "https://zenodo.org/api/records/8111952", "author": "chen, kua; yang,yujing; chen, boqi; hern\u00e1ndez l\u00f3pez\t, jos\u00e9 antonio; mussbacher, gunter; varr\u00f3, d\u00e1niel", "description": "this paper describes a new approach of using llm to automate domain model generation.", "datePublished": "03-07-23", "source_name": "zenodo", "source_identifier": "8111952", "source_url": "https://zenodo.org/records/8111952"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.1109/icme55011.2023.00014", "name": "action-gpt: leveraging large-scale language models for improved and generalized action generation", "url": "https://ieeexplore.ieee.org/document/10219779/", "author": "sai shashank kalakonda; shubh maheshwari; ravi kiran sarvadevabhatla", "description": "we introduce action-gpt, a plug-and-play framework for incorporating large language models (llms) into text-based action generation models. action phrases in current motion capture datasets contain minimal and to-the-point information. by carefully crafting prompts for llms, we generate richer and fine-grained descriptions of the action. we show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. we introduce a generic approach compatible with stochastic (e.g. vae-based) and deterministic (e.g. motionclip) text-to-motion models. in addition, the approach enables multiple text descriptions to be utilized. our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple llm-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. code and pretrained models are available at https://actiongpt.github.io.", "datePublished": "25-08-23", "source_name": "ieee", "source_identifier": "10219779", "source_url": "https://ieeexplore.ieee.org/document/10219779/"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.22364/bjmc.2023.11.3.04", "name": "apple and pear scab expert system.", "url": "https://dblp.org/rec/journals/bjmc/apeinanszll23", "author": "llmars apeinans; imants zarembo; gunars lacis; lienite litavniece", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "21845", "source_url": "https://dblp.org/rec/journals/bjmc/apeinanszll23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.48550/arxiv.2303.12810", "name": "are llms the master of all trades? : exploring domain-agnostic reasoning skills of llms.", "url": "https://dblp.org/rec/journals/corr/abs-2303-12810", "author": "shrivats agrawal", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "283229", "source_url": "https://dblp.org/rec/journals/corr/abs-2303-12810"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1145/3618257.3624845", "name": "an llm-based framework for fingerprinting internet-connected devices.", "url": "https://dblp.org/rec/conf/imc/sarabiyl23", "author": "armin sarabi; tongxin yin; mingyan liu", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "224839", "source_url": "https://dblp.org/rec/conf/imc/sarabiyl23"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1007/s00216-016-9652-3", "name": "a visual assay and spectrophotometric determination of llm-105 explosive using detection of gold nanoparticle aggregation at two ph values", "url": "https://doi.org/10.1007/s00216-016-9652-3", "author": "yang cheng; yi he", "description": "we report a simple, rapid, and sensitive assay for visual and spectrophotometric detection of the 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) explosive. the assay is based on different interactions between llm-105 and gold nanoparticle (aunp) dispersions at two ph values, leading to the formation of dispersed or aggregated aunps. two aunp dispersions at two ph values were applied to recognize and detect llm-105 instead of traditional aunp dispersion under an aptotic ph to improve the anti-interference ability. the developed assay showed excellent sensitivity with a detection limit of 3\u00a0ng/ml, and the presence of as low as 0.2\u00a0\u03bcg/ml llm-105 can be directly detected with the bare eye. this sensitivity is about six orders of magnitude higher than that of the reported traditional assays. additionally, the assay exhibited good selectivity toward llm-105 over other explosives, sulfur-containing compounds, and amines. graphical abstract a simple, sensitive, and selective assay for llm-105 was developed based on the ph-dependent interaction between the llm-105 explosive and gold nanoparticle dispersion.", "datePublished": "26-05-16", "source_name": "openaire products", "source_identifier": "doi_dedup___::0f7d8ab8469519dfaf3e2f52e599f218", "source_url": "https://doi.org/10.1007/s00216-016-9652-3"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.22364/bjmc.2023.11.3.04", "name": "apple and pear scab expert system.", "url": "https://dblp.org/rec/journals/bjmc/apeinanszll23", "author": "llmars apeinans; imants zarembo; gunars lacis; lienite litavniece", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "21845", "source_url": "https://dblp.org/rec/journals/bjmc/apeinanszll23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}, {"identifier": "10.48550/arxiv.2303.12810", "name": "are llms the master of all trades? : exploring domain-agnostic reasoning skills of llms.", "url": "https://dblp.org/rec/journals/corr/abs-2303-12810", "author": "shrivats agrawal", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "283229", "source_url": "https://dblp.org/rec/journals/corr/abs-2303-12810"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/tii.2019.2912625", "name": "an interpretable fuzzy dbn-based classifier for indoor user movement prediction in ambient assisted living applications", "url": "https://ieeexplore.ieee.org/document/8695137/", "author": "xiongtao zhang; fu-lai chung; shitong wang", "description": "in this paper, an interpretable fuzzy deep belief network (dbn)-based classifier called deep belief networks-based takagi-sugeno-kang fuzzy classifier (dbn-tsk-fc) is created for indoor user movement prediction in ambient assisted living applications. with its promising classification performance, dbn-tsk-fc features sharing both the powerful neural representation ability of a dbn and the strong uncertainty-handling capability of an interpretable fuzzy representation. on the one hand, dbn-tsk-fc builds its interpretable fuzzy representation in a hierarchical way by applying the classical fuzzy clustering algorithm fcm to obtain fuzzy partitions on the training dataset. then, it forms interpretable antecedent parts of fuzzy rules as the corresponding fuzzy representation. on the other hand, dbn-tsk-fc builds its dbn-based neural representation in the other hierarchical way. that is, it applies the existing unsupervised dbn pretraining on the training dataset and then takes the neural representation of all the hidden nodes in the top layer of the corresponding dbn as the set of consequent variables of fuzzy rules. in this approach, both the interpretable fuzzy representation and the dbn-based neural representation are further fused to form the corresponding fuzzy rules quickly by using the least learning machine (llm) on both the fuzzy rules and the labeling information of the original dataset. therefore, dbn-tsk-fc is essentially a deep tsk fuzzy classifier from the perspective of fuzzy rules, and it indeed avoids the very slow fine-tuning training required after the unsupervised pretraining of the existing dbn learning. the experimental results on the movementaal_rss dataset indicate the effectiveness of the proposed classifier dbn-tsk-fc.", "datePublished": "22-04-19", "source_name": "ieee", "source_identifier": "8695137", "source_url": "https://ieeexplore.ieee.org/document/8695137/"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1007/s00216-016-9652-3", "name": "a visual assay and spectrophotometric determination of llm-105 explosive using detection of gold nanoparticle aggregation at two ph values", "url": "https://doi.org/10.1007/s00216-016-9652-3", "author": "yang cheng; yi he", "description": "we report a simple, rapid, and sensitive assay for visual and spectrophotometric detection of the 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) explosive. the assay is based on different interactions between llm-105 and gold nanoparticle (aunp) dispersions at two ph values, leading to the formation of dispersed or aggregated aunps. two aunp dispersions at two ph values were applied to recognize and detect llm-105 instead of traditional aunp dispersion under an aptotic ph to improve the anti-interference ability. the developed assay showed excellent sensitivity with a detection limit of 3\u00a0ng/ml, and the presence of as low as 0.2\u00a0\u03bcg/ml llm-105 can be directly detected with the bare eye. this sensitivity is about six orders of magnitude higher than that of the reported traditional assays. additionally, the assay exhibited good selectivity toward llm-105 over other explosives, sulfur-containing compounds, and amines. graphical abstract a simple, sensitive, and selective assay for llm-105 was developed based on the ph-dependent interaction between the llm-105 explosive and gold nanoparticle dispersion.", "datePublished": "26-05-16", "source_name": "openaire products", "source_identifier": "doi_dedup___::0f7d8ab8469519dfaf3e2f52e599f218", "source_url": "https://doi.org/10.1007/s00216-016-9652-3"}, {"identifier": null, "name": "an llm-powered adaptive practicing system.", "url": "https://dblp.org/rec/conf/aied/kabirl23", "author": "md rayhan kabir; fuhua lin", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167618", "source_url": "https://dblp.org/rec/conf/aied/kabirl23"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "a case study using large language models to generate metadata for math questions.", "url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23", "author": "katie bainbridge; candace a. walkington; armon ibrahim; iris zhong; debshila basu mallick; julianna washington; richard g. baraniuk", "description": null, "datePublished": "2023", "source_name": "dblp", "source_identifier": "167534", "source_url": "https://dblp.org/rec/conf/aied/bainbridgewizmw23"}, {"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}]}], "match": [{"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://doi.org/10.1016/j.enmf.2020.12.001", "author": "xu rong; hongzhen li; chen dong; xiaoqing zhou; hao shilong; xin zhou", "description": "abstract   sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, and spherical shapes, were prepared using a solution crystallization method, and their crystal characteristics and sensitivity were investigated. it was found that the h50 values (impact sensitivity) of llm-105 vary within an extremely wide range of 33.8\u2013112.2\u202fcm and are mainly influenced by the particle morphology, crystal integrity, particle surface defects, and roughness, but are mostly independent of intracrystalline defects and particle sizes. the friction sensitivities of all samples are zero and are unaffected by the crystal characteristics. the g50 values (shock sensitivity) are within the range of 0\u20136.9\u202fmm, increasing with decreasing particle sizes and the apparent crystal density. notably, llm-105 crystals with a spherical shape, good integrity, smooth surface, and fewer defects are insensitive to impact and shock impulse. the relationships between the crystal characteristics and the sensitivity of llm-105 are extremely complex and show some abnormal phenomena, which can be attributed to the crystal packing style and aggregated microstructures of llm-105.", "datePublished": "01-12-20", "source_name": "openaire products", "source_identifier": "doi_________::737c8c201b09102a84bacf3fa4022ba4", "source_url": "https://doi.org/10.1016/j.enmf.2020.12.001"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://doi.org/10.1039/d0cp02159h", "author": "ying yin; hongzhen li; qian yu; longyu liao; jinshan li; heliang sui; chuande zhao", "description": "2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) is a representative of the new generation of low-sensitivity energetic materials and has been applied extensively in formulations as an insensitive high-energetic ingredient. although the initial thermal decomposition mechanism of llm-105 has been studied based on quantum chemical calculations, the internal mechanism of the two-step thermal decomposition still lacks experimental research. thus, this study involves a detailed experimental study to reveal the mechanism of the two-step thermal decomposition of llm-105. the results showed that llm-105 decay was a consecutive reaction. the first-step reaction dominated the early stage of the llm-105 decomposition, and its products participated in the reaction of the second step. the cleavage of no2 and nh2 groups of llm-105 mainly occurred in the first step, while gaseous products no and c2n2 were released during the second reaction step. the first-step reaction had a higher oxygen consumption rate and a lower carbon consumption rate, producing more heat due to more extensive oxidation of the carbon backbone. the difference in the oxidative ability and reaction rate between the two steps resulted in a two-step exothermic and mass loss behavior. this study provides further insights into the entire reaction process of llm-105 and would be helpful for its better application and for the design of new explosives.", "datePublished": "01-01-20", "source_name": "openaire products", "source_identifier": "doi_dedup___::a4e3ca635e6a69058303d9f593edfc17", "source_url": "https://doi.org/10.1039/d0cp02159h"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://ieeexplore.ieee.org/document/6090694/", "author": "panagiotis d. bamidis; evdokimos i. konstantinidis; antonis billis; christos frantzidis; magda tsolaki; walter hlauschek; efthyvoulos kyriacou; marios neofytou; constantinos s. pattichis", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "ieee", "source_identifier": "6090694", "source_url": "https://ieeexplore.ieee.org/document/6090694/"}, {"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://zenodo.org/api/records/2555897", "author": "bamidis, p.d.; konstantinidis, e.i.; billis, a.; fratzidis, ch.; tsolaki, m.; hlauschek, w.; kyriacou, e.c.; neophytou, m.s.; pattichis, c.s.", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "zenodo", "source_identifier": "2555897", "source_url": "https://zenodo.org/records/2555897"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://doi.org/10.1016/j.enmf.2020.12.001", "author": "xu rong; hongzhen li; chen dong; xiaoqing zhou; hao shilong; xin zhou", "description": "abstract   sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, and spherical shapes, were prepared using a solution crystallization method, and their crystal characteristics and sensitivity were investigated. it was found that the h50 values (impact sensitivity) of llm-105 vary within an extremely wide range of 33.8\u2013112.2\u202fcm and are mainly influenced by the particle morphology, crystal integrity, particle surface defects, and roughness, but are mostly independent of intracrystalline defects and particle sizes. the friction sensitivities of all samples are zero and are unaffected by the crystal characteristics. the g50 values (shock sensitivity) are within the range of 0\u20136.9\u202fmm, increasing with decreasing particle sizes and the apparent crystal density. notably, llm-105 crystals with a spherical shape, good integrity, smooth surface, and fewer defects are insensitive to impact and shock impulse. the relationships between the crystal characteristics and the sensitivity of llm-105 are extremely complex and show some abnormal phenomena, which can be attributed to the crystal packing style and aggregated microstructures of llm-105.", "datePublished": "01-12-20", "source_name": "openaire products", "source_identifier": "doi_________::737c8c201b09102a84bacf3fa4022ba4", "source_url": "https://doi.org/10.1016/j.enmf.2020.12.001"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://doi.org/10.1039/d0cp02159h", "author": "ying yin; hongzhen li; qian yu; longyu liao; jinshan li; heliang sui; chuande zhao", "description": "2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) is a representative of the new generation of low-sensitivity energetic materials and has been applied extensively in formulations as an insensitive high-energetic ingredient. although the initial thermal decomposition mechanism of llm-105 has been studied based on quantum chemical calculations, the internal mechanism of the two-step thermal decomposition still lacks experimental research. thus, this study involves a detailed experimental study to reveal the mechanism of the two-step thermal decomposition of llm-105. the results showed that llm-105 decay was a consecutive reaction. the first-step reaction dominated the early stage of the llm-105 decomposition, and its products participated in the reaction of the second step. the cleavage of no2 and nh2 groups of llm-105 mainly occurred in the first step, while gaseous products no and c2n2 were released during the second reaction step. the first-step reaction had a higher oxygen consumption rate and a lower carbon consumption rate, producing more heat due to more extensive oxidation of the carbon backbone. the difference in the oxidative ability and reaction rate between the two steps resulted in a two-step exothermic and mass loss behavior. this study provides further insights into the entire reaction process of llm-105 and would be helpful for its better application and for the design of new explosives.", "datePublished": "01-01-20", "source_name": "openaire products", "source_identifier": "doi_dedup___::a4e3ca635e6a69058303d9f593edfc17", "source_url": "https://doi.org/10.1039/d0cp02159h"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://ieeexplore.ieee.org/document/6090694/", "author": "panagiotis d. bamidis; evdokimos i. konstantinidis; antonis billis; christos frantzidis; magda tsolaki; walter hlauschek; efthyvoulos kyriacou; marios neofytou; constantinos s. pattichis", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "ieee", "source_identifier": "6090694", "source_url": "https://ieeexplore.ieee.org/document/6090694/"}, {"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://zenodo.org/api/records/2555897", "author": "bamidis, p.d.; konstantinidis, e.i.; billis, a.; fratzidis, ch.; tsolaki, m.; hlauschek, w.; kyriacou, e.c.; neophytou, m.s.; pattichis, c.s.", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "zenodo", "source_identifier": "2555897", "source_url": "https://zenodo.org/records/2555897"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://doi.org/10.1016/j.enmf.2020.12.001", "author": "xu rong; hongzhen li; chen dong; xiaoqing zhou; hao shilong; xin zhou", "description": "abstract   sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, and spherical shapes, were prepared using a solution crystallization method, and their crystal characteristics and sensitivity were investigated. it was found that the h50 values (impact sensitivity) of llm-105 vary within an extremely wide range of 33.8\u2013112.2\u202fcm and are mainly influenced by the particle morphology, crystal integrity, particle surface defects, and roughness, but are mostly independent of intracrystalline defects and particle sizes. the friction sensitivities of all samples are zero and are unaffected by the crystal characteristics. the g50 values (shock sensitivity) are within the range of 0\u20136.9\u202fmm, increasing with decreasing particle sizes and the apparent crystal density. notably, llm-105 crystals with a spherical shape, good integrity, smooth surface, and fewer defects are insensitive to impact and shock impulse. the relationships between the crystal characteristics and the sensitivity of llm-105 are extremely complex and show some abnormal phenomena, which can be attributed to the crystal packing style and aggregated microstructures of llm-105.", "datePublished": "01-12-20", "source_name": "openaire products", "source_identifier": "doi_________::737c8c201b09102a84bacf3fa4022ba4", "source_url": "https://doi.org/10.1016/j.enmf.2020.12.001"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://doi.org/10.1039/d0cp02159h", "author": "ying yin; hongzhen li; qian yu; longyu liao; jinshan li; heliang sui; chuande zhao", "description": "2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) is a representative of the new generation of low-sensitivity energetic materials and has been applied extensively in formulations as an insensitive high-energetic ingredient. although the initial thermal decomposition mechanism of llm-105 has been studied based on quantum chemical calculations, the internal mechanism of the two-step thermal decomposition still lacks experimental research. thus, this study involves a detailed experimental study to reveal the mechanism of the two-step thermal decomposition of llm-105. the results showed that llm-105 decay was a consecutive reaction. the first-step reaction dominated the early stage of the llm-105 decomposition, and its products participated in the reaction of the second step. the cleavage of no2 and nh2 groups of llm-105 mainly occurred in the first step, while gaseous products no and c2n2 were released during the second reaction step. the first-step reaction had a higher oxygen consumption rate and a lower carbon consumption rate, producing more heat due to more extensive oxidation of the carbon backbone. the difference in the oxidative ability and reaction rate between the two steps resulted in a two-step exothermic and mass loss behavior. this study provides further insights into the entire reaction process of llm-105 and would be helpful for its better application and for the design of new explosives.", "datePublished": "01-01-20", "source_name": "openaire products", "source_identifier": "doi_dedup___::a4e3ca635e6a69058303d9f593edfc17", "source_url": "https://doi.org/10.1039/d0cp02159h"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.48366/r597838", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r597838", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otc4mzg="}, {"identifier": "10.48366/r598090", "name": "a comparison on foundation large language models", "url": "https://doi.org/10.48366/r598090", "author": "sanju tiwari", "description": "this comparison analyzes how the current advances in foundational\nllm, like gpt-3,  rebel, palm, bloom, opt are compared with its different parameter.", "datePublished": "01-01-23", "source_name": "resodate", "source_identifier": "ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota=", "source_url": "https://resodate.org/resources/ahr0chm6ly9kb2kub3jnlzewljq4mzy2l1i1otgwota="}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://ieeexplore.ieee.org/document/6090694/", "author": "panagiotis d. bamidis; evdokimos i. konstantinidis; antonis billis; christos frantzidis; magda tsolaki; walter hlauschek; efthyvoulos kyriacou; marios neofytou; constantinos s. pattichis", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "ieee", "source_identifier": "6090694", "source_url": "https://ieeexplore.ieee.org/document/6090694/"}, {"identifier": "10.1109/iembs.2011.6090694", "name": "a web services-based exergaming platform for senior citizens: the long lasting memories project approach to e-health care", "url": "https://zenodo.org/api/records/2555897", "author": "bamidis, p.d.; konstantinidis, e.i.; billis, a.; fratzidis, ch.; tsolaki, m.; hlauschek, w.; kyriacou, e.c.; neophytou, m.s.; pattichis, c.s.", "description": "this piece of research describes an innovative e-health service that supports the cognitive and physical training of senior citizens and promotes their active ageing. the approach is adopted by the long lasting memories (llm) project, elements of which are discussed herein in the light of the functionalities provided to the users and the therapists. the aim of this work is to describe those technical elements that demonstrate the unique and integrative character of the llm service, which is based on a modular web service architecture, rendering the system available in different settings like the homes of seniors. the underlying database as well as the remote user interface empower therapists to set personalized training schemes, to view the progress of training sessions, as well as, adding new games and exercises into the system, thereby increasing the services sustainability and marketability.", "datePublished": "01-12-11", "source_name": "zenodo", "source_identifier": "2555897", "source_url": "https://zenodo.org/records/2555897"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://openalex.org/w3112992816", "author": "hongzhen li; xin zhou; run xu; shilong hao; dong chen; xin zhou", "description": "sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, spherical shapes, were prepared using a solution crystallization method, their crystal characteristics sensitivity investigated. it was found that h50 values (impact sensitivity) llm-105 vary within an extremely wide range 33.8\u2013112.2 cm are mainly influenced by particle morphology, integrity, surface defects, roughness, but mostly independent intracrystalline defects sizes. the friction sensitivities all samples zero unaffected characteristics. g50 (shock 0\u20136.9 mm, increasing decreasing sizes apparent density. notably, shape, good smooth surface, fewer insensitive to impact shock impulse. relationships between complex show some abnormal phenomena, which can be attributed packing style aggregated microstructures llm-105.", "datePublished": "01-12-20", "source_name": "openalex", "source_identifier": "w3112992816", "source_url": "https://openalex.org/w3112992816"}, {"identifier": "10.1016/j.enmf.2020.12.001", "name": "anomalous sensitivity related to crystal characteristics of 2,6-diamino-3,5-dinitropyrazing-1-oxide (llm-105)", "url": "https://doi.org/10.1016/j.enmf.2020.12.001", "author": "xu rong; hongzhen li; chen dong; xiaoqing zhou; hao shilong; xin zhou", "description": "abstract   sensitivity is one of the greatest concerns in explosive materials, and its underlying mechanism remains ambiguous. in this study, 2,6-diamino-3,5- dinitropyrazine -1-oxide (llm-105) crystals with different morphologies, such as crosswise, needle, plate, block, diamond, and spherical shapes, were prepared using a solution crystallization method, and their crystal characteristics and sensitivity were investigated. it was found that the h50 values (impact sensitivity) of llm-105 vary within an extremely wide range of 33.8\u2013112.2\u202fcm and are mainly influenced by the particle morphology, crystal integrity, particle surface defects, and roughness, but are mostly independent of intracrystalline defects and particle sizes. the friction sensitivities of all samples are zero and are unaffected by the crystal characteristics. the g50 values (shock sensitivity) are within the range of 0\u20136.9\u202fmm, increasing with decreasing particle sizes and the apparent crystal density. notably, llm-105 crystals with a spherical shape, good integrity, smooth surface, and fewer defects are insensitive to impact and shock impulse. the relationships between the crystal characteristics and the sensitivity of llm-105 are extremely complex and show some abnormal phenomena, which can be attributed to the crystal packing style and aggregated microstructures of llm-105.", "datePublished": "01-12-20", "source_name": "openaire products", "source_identifier": "doi_________::737c8c201b09102a84bacf3fa4022ba4", "source_url": "https://doi.org/10.1016/j.enmf.2020.12.001"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://openalex.org/w2949033303", "author": "tingting luo; yi wang; hao huang; feifei shang; xiaolan song", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) was prepared by the electrospinning method. the morphology and structure of nanofiber characterized scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), photoelectron (xps), brunauer-emmett-teller (bet). nanofibers possessed three-dimensional (3d) net large specific surface area. thermal analysis, performance, sensitivities were investigated, they compared nc/gap llm-105 nanoparticles. nc/gap/nano-llm-105 show higher decomposition rates lower temperatures. decomposed to co2, co, h2o, n2o, few no, -ch2o-, -ch- fragments, thermal-infrared spectrometry online (tg-ir) measurement. demonstrated standard impulse (isp), combustion chamber temperature (tc), specialty height (h50). introduction nano-llm-105 matrix results improvement performance safety.", "datePublished": "04-06-19", "source_name": "openalex", "source_identifier": "w2949033303", "source_url": "https://openalex.org/w2949033303"}, {"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}]}, {"__class__": "tuple", "__value__": [{"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://openalex.org/w3029856680", "author": "yu qian; chuande zhao; longyu liao; hongzhen li; heliang sui; ying yin; jinshan li", "description": "the thermal decomposition mechanism of the consecutive reactions llm-105 was investigated based on gaseous products and solid reactants.", "datePublished": "01-01-20", "source_name": "openalex", "source_identifier": "w3029856680", "source_url": "https://openalex.org/w3029856680"}, {"identifier": "10.1039/d0cp02159h", "name": "a mechanism for two-step thermal decomposition of 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105)", "url": "https://doi.org/10.1039/d0cp02159h", "author": "ying yin; hongzhen li; qian yu; longyu liao; jinshan li; heliang sui; chuande zhao", "description": "2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) is a representative of the new generation of low-sensitivity energetic materials and has been applied extensively in formulations as an insensitive high-energetic ingredient. although the initial thermal decomposition mechanism of llm-105 has been studied based on quantum chemical calculations, the internal mechanism of the two-step thermal decomposition still lacks experimental research. thus, this study involves a detailed experimental study to reveal the mechanism of the two-step thermal decomposition of llm-105. the results showed that llm-105 decay was a consecutive reaction. the first-step reaction dominated the early stage of the llm-105 decomposition, and its products participated in the reaction of the second step. the cleavage of no2 and nh2 groups of llm-105 mainly occurred in the first step, while gaseous products no and c2n2 were released during the second reaction step. the first-step reaction had a higher oxygen consumption rate and a lower carbon consumption rate, producing more heat due to more extensive oxidation of the carbon backbone. the difference in the oxidative ability and reaction rate between the two steps resulted in a two-step exothermic and mass loss behavior. this study provides further insights into the entire reaction process of llm-105 and would be helpful for its better application and for the design of new explosives.", "datePublished": "01-01-20", "source_name": "openaire products", "source_identifier": "doi_dedup___::a4e3ca635e6a69058303d9f593edfc17", "source_url": "https://doi.org/10.1039/d0cp02159h"}]}, {"__class__": "tuple", "__value__": [{"identifier": null, "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "http://www.wikidata.org/entity/q92543898", "author": "yi wang; hao huang; tingting luo; feifei shang; xiaolan song", "description": null, "datePublished": "04-06-19", "source_name": "wikidata", "source_identifier": "entity/q92543898", "source_url": "http://www.wikidata.org/entity/q92543898"}, {"identifier": "10.3390/nano9060854", "name": "an electrospun preparation of the nc/gap/nano-llm-105 nanofiber and its properties", "url": "https://doi.org/10.3390/nano9060854", "author": "hao huang; tingting luo; yi wang; xiaolan song; feifei shang", "description": "in this work, an energetic composite fiber, in which 2,6-diamino-3,5-dinitropyrazine-1-oxide (llm-105) nanoparticles intimately incorporated with a nitrocellulose/glycidyl azide polymer (nc/gap) fiber, was prepared by the electrospinning method. the morphology and structure of the nanofiber was characterized by scanning electron microscopy (sem), energy dispersive x-ray (edx), fourier transform infrared spectroscopy (ir), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), and brunauer\u2212emmett\u2212teller (bet). the nanofibers possessed a three-dimensional (3d) net structure and a large specific surface area. thermal analysis, energetic performance, and sensitivities were investigated, and they were compared with nc/gap and llm-105 nanoparticles. the nc/gap/nano-llm-105 nanofibers show higher decomposition rates and lower decomposition temperatures. the nc/gap/nano-llm-105 decomposed to co2, co, h2o, n2o, and a few no, -ch2o-, and -ch- fragments, in the thermal-infrared spectrometry online (tg-ir) measurement. the nc/gap/nano-llm-105 nanofibers demonstrated a higher standard specific impulse (isp), a higher combustion chamber temperature (tc), and a higher specialty height (h50). the introduction of nano-llm-105 in the nc/gap matrix results in an improvement in energetic performance and safety.", "datePublished": "04-06-19", "source_name": "openaire products", "source_identifier": "doi_dedup___::d7e2c86769c5937e09cfc05be2974e52", "source_url": "https://doi.org/10.3390/nano9060854"}]}]}